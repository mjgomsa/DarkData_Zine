<!DOCTYPE html>
<html>

<head>
    <meta charset="UTF-8">
    <title>Your Article Title</title>
    <link rel="stylesheet" type="text/css" href="/styling/style.css">
</head>

<body>
    <script>
 function toggleImgHover(clickedElement) {
    var imgHoverClicked = clickedElement.querySelector('.img-hover');

    // Check if the clicked container already has the 'active' class
    if (imgHoverClicked.classList.contains('active')) {
      // Toggle off if already active
      imgHoverClicked.classList.remove('active');
    } else {
      // Get all image containers
      var imageContainers = document.querySelectorAll('.image-container');

      // Loop through all containers to reset img-hover display
      imageContainers.forEach(function(container) {
        var imgHover = container.querySelector('.img-hover');
        imgHover.classList.remove('active');
      });

      // Toggle on for the clicked container
      imgHoverClicked.classList.add('active');
    }
  }
      </script>
    <header>
        <div class="header-content">
            <div class="header-text">
                <h1>Can 10 Design Principles Govern AI?</h1>
                <a href="tag1.html" class="box">
                    
                    <div class="info">
                        <h4> by Max Emrich</h4>
                    </div>
                </a>
                <p class="abstract">AI is progressing rapidly, and hardware devices centered around AI, like Humane's
                    AIPin, are emerging. However, the Collingridge Dilemma poses a challenge in influencing the
                    development of AI. Sam Altman suggests being thoughtful about the risks and building technology that
                    mitigates them.</p>
                
                <div class="tags">
                    <a href="tag1.html" class="box">
                        <div class="circle AIHardware"> </div>
                        <div class="info">
                            <h4>AI Hardware</h4>
                        </div>
                    </a>
                    <a href="tag2.html" class="box">
                        <div class="circle DesignEthics"> </div>
                        <div class="info">
                            <h4>Design Ethics</h4>
                        </div>
                    </a>
                    <a href="tag3.html" class="box">
                        <div class="circle TechnologyGovernance "> </div>
                        <div class="info">
                            <h4>Technology Governance</h4>
                        </div>
                    </a>
                    <a href="tag2.html" class="box">
                        <div class="circle PrivacyConcerns"> </div>
                        <div class="info">
                            <h4>Privacy Concerns</h4>
                        </div>
                    </a>
                    <a href="tag3.html" class="box">
                        <div class="circle EthicalAI"> </div>
                        <div class="info">
                            <h4>Ethical AI</h4>
                        </div>
                    </a>
                </div>
            </div>
            <div class="header-image">
                <img class="mobile" src="assets/max_article/1_2.png" alt="Header Image">
            </div>
        </div>
    </header>

    <main>
        <article>
            <p>AI is progressing rapidly, and hardware devices centered around AI, like Humane's AIPin, are emerging.
                However, the Collingridge Dilemma poses a challenge in influencing the development of AI. Sam Altman
                suggests being thoughtful about the risks and building technology that mitigates them. Humane's ten
                design principles for good AI draw parallels to Dieter Rams' principles for good design. The principles
                aim to guide the responsible development of AI, but questions remain about whether they can fully
                control the implications of AI hardware products.

            </p>
            <p>AI has been progressing faster than we all suspected. And while AI for now has been restricted to
                software, we will very soon see the first hardware devices centred around AI.</p>

            <div class="image-container row1" onclick="toggleImgHover(this)">
                <img src="assets/max_article/6.png" alt="Image 1 Description">
                <img class="img-hover wide" src="assets/max_article/6.png" alt="Image 1 Description">
                <figcaption>Imran Chaudhri: The disappearing computer - and a world where you can take AI everywhere
                    | TED Talk, April 2023.</figcaption>
            </div>
            <p>One of these devices is Humane’s AIPin. Described by Humane's founder Imran Chaudhri as a seamless,
                screenless and sensing experience
                <sup><span class="footnote"><a rel="noopener" href="#Bibliography">1 </a>
                        <span class="footnote-content">
                            Chaudhri, Imran. “The Disappearing Computer - and a World Where You Can Take Ai Everywhere.”
                            Imran Chaudhri: The disappearing computer - and a world where you can take AI everywhere |
                            TED Talk, April 2023.
                        </span>
                    </span></sup> the palm-sized device is fitted to the user's clothing
                at chest level. Equipped with microphones, speakers, a camera and a projector, it is the first
                generation of a conversational AI that follows you through life. Dreamed up by a team of former
                designers at Apple, it is their version of the “next big thing”, replacing phones.
            </p>

            <p>But when new technology, like AI, is in its early stages of development, we run into a conundrum known as
                the Collingridge Dilemma, where “it is still possible to influence the direction of its development, but
                we do not know yet how it will affect society. Yet, when the technology has become societally embedded,
                we do know its implications, but it is very difficult to influence its development.” <sup><span
                        class="footnote"><a rel="noopener" href="#Bibliography">2
                        </a>
                        <span class="footnote-content">
                            Stern, Joanna, Mira Murati, and Sam Altman. “A Conversation with OpenAI’s Sam Altman and
                            Mira Murati.” WSJ, October 20, 2023.
                        </span></sup>
            <p>Sam Altman, the founder of OpenAI, described this dilemma at the WSJ 2023 Conference: “it would be a
                moral failing not to go pursue [AI] for humanity.” While mentioning at the same time that “[as] with
                other technologies, we've got to address the downsides that come along with this.” He offers a bit more
                insight into his strategy around this dilemma. According to him, you have to be ”thoughtful about the
                risks”, “try to measure what the capabilities are”, and “build your own technology in a way that
                mitigates those risks.<sup><span class="footnote"><a rel="noopener" href="#Bibliography">3
                        </a>
                        <span class="footnote-content">
                            Kudina, Olya, and Peter-Paul Verbeek. “Ethics from within: Google Glass, the Collingridge
                            Dilemma, and the Mediated Value of Privacy.” Science, Technology, &amp; Human Values 44, no.
                            2 (2018): 291–314.
                        </span>
                    </span></sup>
            <div  class="quote" ><h1>“As AI advances, we will see how it will transform
                every aspect of our lives in ways that seem unimaginable right now.”</h1></div>
            <p>Humane’s CEO Imran Chaudhri more indirectly acknowledges this conundrum during the first-ever public demo
                of the Human AIPin during a TED Talk by mentioning, “As AI advances, we will see how it will transform
                every aspect of our lives in ways that seem unimaginable right now.” <sup><span class="footnote"><a
                            rel="noopener" href="#Bibliography">4
                        </a>
                        <span class="footnote-content">
                            Chaudhri, Imran. “The Disappearing Computer - and a World Where You Can Take Ai Everywhere.”
                            Imran Chaudhri: The disappearing computer - and a world where you can take AI everywhere |
                            TED Talk, April 2023.
                        </span>
                    </span></sup> Not trying to
                anticipate these changes, it seems like Humane leaves the consumer to explore these Unimaginables as
                part of a sociotechnical experiment. Unimagineables that, according to van de Poel, “are inherent in
                social changes induced by technological development” <sup><span class="footnote"><a rel="noopener"
                            href="#Bibliography">5
                        </a>
                        <span class="footnote-content">
                            Poel, Ibo van de. “An Ethical Framework for Evaluating Experimental Technology.” Science and
                            Engineering Ethics 22, no. 3 (2015): 667–86.
                        </span>
                    </span></sup> </p>
            <div class="image-container row41" onclick="toggleImgHover(this)">
                <img src="assets/max_article/7.jpg" alt="Image 1 Description">
                <img class="img-hover height" src="assets/max_article/7.jpg" alt="Image 1 Description">
                <figcaption>Google</figcaption>
            </div>
            <div class="image-container row42" onclick="toggleImgHover(this)">
                <img src="assets/max_article/8.jpg" alt="Image 2 Description">
                <img class="img-hover height" src="assets/max_article/8.jpg" alt="Image 2 Description">
                <figcaption>Google </figcaption>
            </div>
            <div class="image-container row43" onclick="toggleImgHover(this)">
                <img src="assets/max_article/9.jpg" alt="Image 3 Description">
                <img class="img-hover height" src="assets/max_article/9.jpg" alt="Image 3 Description">
                <figcaption>Humane, Inc.</figcaption>
            </div>
            <div class="image-container row44" onclick="toggleImgHover(this)">
                <img src="assets/max_article/10.jpg" alt="Image 4 Description">
                <img class="img-hover height" src="assets/max_article/10.jpg" alt="Image 4 Description">
                <figcaption>Humane, Inc. </figcaption>
            </div>
            <p>Already having taken a page from the Google Glass playbook by presenting their technology through a
                fashion show and trying to raise the product's acceptance, we can start drawing parallels between the
                2012 Google Glasses and Humane’s 2023 AIPin and use them to unpack some of these Unimaginables. Both the
                Google Glasses and Humanes AIPin were and are new technologies that, for the first time, were made
                available to end users in a hardware product. What is described as “augment[ing] human perception by
                providing an additional layer of information that blurs the boundary between the public and the private
                in new ways” <sup><span class="footnote"><a rel="noopener" href="#Bibliography">6
                        </a>
                        <span class="footnote-content">
                            Kudina, Olya, and Peter-Paul Verbeek. “Ethics from within: Google Glass, the Collingridge
                            Dilemma, and the Mediated Value of Privacy.” Science, Technology, &amp; Human Values 44, no.
                            2 (2018): 291–314.
                        </span>
                    </span></sup>
                in a paper on Google Glass, also applies to Humane’s AIPin.</p>
            <p>With the ultimate failure of Google Glass as a consumer good, Humane will need a strategy for success. As
                such, Humane has a collection of ten guiding design principles that aim to guide how they work with AI.
                With many of Humane's team members coming with a long experience at Apple and its design teams, the
                exact number of ten principles is no coincidence. Apple's design is heavily inspired by the work of
                Dieter Rams at Braun, and we can draw a direct connection between Ram's ten Principles for good design
                and Humane’s ten principles for good AI. In fact, posters that display Ram's ten principles are so
                similar to Humane’s version that I am sure one of them was in the room when the humane team wrote their
                own.</p>
            <div class="image-container row21" onclick="toggleImgHover(this)">
                <img src="assets/max_article/11.png" alt="Image 5 Description">
                <img class="img-hover height" src="assets/max_article/11.png" alt="Image 5 Description">
                <figcaption>Dieter Rams</figcaption>
            </div>
            <div class="image-container row22" onclick="toggleImgHover(this)">
                <img src="assets/max_article/12.png" alt="Image 6 Description">
                <img class="img-hover height" src="assets/max_article/12.png" alt="Image 6 Description">
                <figcaption>Humane, Inc. </figcaption>
            </div>
            <p>Before we look into the difference between individual principles, it is crucial to notice the extreme
                difference in context. For once, we live in a different century, and as Darius Ou states, “If we always
                follow the rules set by designers who lived in the 20th century—but we live in the 21st century—then
                what are we following? Are we blindly following?” <sup><span class="footnote"><a rel="noopener"
                            href="#Bibliography">7
                        </a>
                        <span class="footnote-content">
                            Zhuang, Justin. “Lessons in the ‘New Ugly’ School of Design.” Aiga Eye on Design, January
                            11, 2019.
                        </span>
                    </span></sup> But, and this is even more significant,
                while Ram's ten rules for good design focus on the practice of design, Humane's ten principles for good
                AI assume responsibility for a whole company, its users and all their activities related to a specific
                piece of technology. This expands the scope of the ten principles from a single discipline to a
                transdisciplinary level and leaves us with the question: Can ten design principles control the
                implications of an AI hardware product? A product that Imran Chaudhri and Bethany Bongiorno, the
                Co-Founders of Humane, describe as “an opportunity for people to take AI with them everywhere and to
                unlock a new era of personal mobile computing which is seamless, screenless and sensing.” <sup><span
                        class="footnote"><a rel="noopener" href="#Bibliography">8
                        </a>
                        <span class="footnote-content">
                            Chaudhri, Imran. “The Disappearing Computer - and a World Where You Can Take Ai Everywhere.”
                            Imran Chaudhri: The disappearing computer - and a world where you can take AI everywhere |
                            TED Talk, April 2023.
                        </span>
                    </span></sup>
            </p>
            <p>We will take a look into some of the differences and similarities between the two versions of the ten
                principles. As part of this comparison, we will draw parallels between the Google Glasses and the Human
                AI Pin. This helps us to understand the broader context under which each principle operates, as well as
                its effectiveness and shortcomings.
            </p>

        </article>

    </main>

    <footer>
        
        <div class="Bibliography">
            <a id="Bibliography"></a>
            <h2>Bibliography: </h2>
            <div class="Num"><h1>01</h1></div>
            <p> <b>Chaudhri, Imran. “The Disappearing Computer - and a World Where You Can Take Ai Everywhere.”</b> Imran
                Chaudhri: The disappearing computer - and a world where you can take AI everywhere | TED Talk, April
                2023. https://www.ted.com/talks/imran_chaudhri_the_disappearing_computer_and_a_world_where_you_can_take_ai_everywhere.
            </p>
            <div class="Num"><h1>02</h1></div>
            <p> <b>Kudina, Olya, and Peter-Paul Verbeek. “Ethics from within: Google Glass, the Collingridge Dilemma, and
                the Mediated Value of Privacy.”</b> *Science, Technology, &amp; Human Values* 44, no. 2 (2018): 291–314.
                https://doi.org/10.1177/0162243918793711.</p>
            <div class="Num"><h1>03</h1></div>
            <p><b>Stern, Joanna, Mira Murati, and Sam Altman. “A Conversation with OpenAI’s Sam Altman and Mira Murati.”</b>
                WSJ, October 20, 2023. https://open.spotify.com/episode/6JE1wksSOkMApOuwqiN9BK?si=126807ed409a427b.</p>
            <div class="Num"><h1>04</h1></div>
            <p><b>Poel, Ibo van de. “An Ethical Framework for Evaluating Experimental Technology.” </b>*Science and
                Engineering Ethics* 22, no. 3 (2015): 667–86. https://doi.org/10.1007/s11948-015-9724-3.</p>
            <div class="Num"><h1>05</h1></div>
            <p><b>Humane. “Humane Reveals the Name of First Device, the Humane AI Pin.”</b> Humane News, 2023.
                https://hu.ma.ne/media/humane-names-first-device-humane-ai-pin.</p>
            <div class="Num"><h1>06</h1></div>
            <p><b>Zhuang, Justin. “Lessons in the ‘New Ugly’ School of Design.”</b> Aiga Eye on Design, January 11, 2019.
                https://eyeondesign.aiga.org/schooled-in-the-new-ugly-lessons-from-darius-ous-autotypography/.</p>
            <!-- Add more references as needed -->
        </div>
    </footer>

    <article>
        <div class="recommended-articles"><h2>Explore related themes: </h2></div>
        <section class="recommended-articles">
            <div class="article-box">
                <img src="assets/max_article/3.png" alt="Article 1 Image">
                <div class="article-content">
                    <h3>Click the Earth</h3>
                    <div class="tags">
                        <a href="tag1.html" class="box">
                            <div class="circle AIHardware"> </div>
                            <div class="info">
                                <h4>AI Hardware</h4>
                            </div>
                        </a>
                        <a href="tag2.html" class="box">
                            <div class="circle PrivacyConcerns"> </div>
                            <div class="info">
                                <h4>Privacy Concerns</h4>
                            </div>
                        </a>
                        <a href="tag2.html" class="box">
                            <div class="circle DesignEthics"> </div>
                            <div class="info">
                                <h4>Design Ethics</h4>
                            </div>
                        </a>
                    </div>
                </div>
            </div>
            <div class="article-box">
                <img src="/assets/max_article/4.png" alt="Article 2 Image">
                <div class="article-content">
                    <h3>The Decolonial Web? On Colonial Infrastructure and Reclaiming Data</h3>
                    <div class="tags">
                        <a href="tag1.html" class="box">
                            <div class="circle AIHardware"> </div>
                            <div class="info">
                                <h4>AI Hardware</h4>
                            </div>
                        </a>
                        <a href="tag2.html" class="box">
                            <div class="circle DesignEthics"> </div>
                            <div class="info">
                                <h4>Design Ethics</h4>
                            </div>
                        </a>
                    </div>
                    
                </div>
            </div>
            <div class="article-box" id="remove">
                <img src="assets/max_article/5.png" alt="Article 3 Image">
                <div class="article-content">
                    <h3>Digital Detoxes, Data Leakage and Me</h3>
                    <div class="tags">
                        <a href="tag3.html" class="box">
                            <div class="circle TechnologyGovernance "> </div>
                            <div class="info">
                                <h4>Technology Governance</h4>
                            </div>
                        </a>
                        <a href="tag2.html" class="box">
                            <div class="circle PrivacyConcerns"> </div>
                            <div class="info">
                                <h4>Privacy Concerns</h4>
                            </div>
                        </a>
                        <a href="tag3.html" class="box">
                            <div class="circle EthicalAI"> </div>
                            <div class="info">
                                <h4>Ethical AI</h4>
                            </div>
                        </a>
                    </div>
                </div>
            </div>
        </div>
        </section>
    </article>
</body>

</html>